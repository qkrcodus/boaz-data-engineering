#### 출처 : 우아콘2023 , 데브원영 , 우아한 기술 블로그
### 최종본 

배민은 이벤트 기반 아키텍쳐를 사용합니다. 이 아키텍쳐에서는
1. 메시지 처리 순서를 유지하기 위해 Kafka를 사용합니다.
2. 메시지 발행 순서와 누락 방지를 보장하기 위해 Transactional Outbox Pattern을 사용합니다.
3. 실시간 데이터 분석을 위해 Kafka Streams를 적용하며, 분석된 데이터를 장기적으로 저장하고 활용하기 위해 다양한 클라우드 기반 데이터 저장소를 활용합니다.
이런 순서로 정리했습니다!!

저희는 배달의 민족의 주력 서비스인 배달 시스템에 초점을 맞추어 데이터 파이프라인을 조사해 보았습니다.

배달의 민족 딜리버리 서비스는 고객의 주문 생성부터 라이더 음식 전달까지의 전 과정을 실시간으로 처리합니다.
배달 프로세스는 아래 그림과 같습니다. 배달이 진행되며 배달 상태는 배달 생성, 배차 완료, 픽업 완료, 전달 완료 순서대로 변경되고, 여러 이벤트가 발행됩니다. 이벤트 발행과 관련하여 순서를 보장하는 것은 매우 중요합니다. 

예를 들어 배차 완료와 픽업 준비 요청이 거의 동시에 발생할 수 있습니다. 프로듀서는 배차 완료 이후 픽업 준비 요청을 발행하였으나 네트워크 등의 이슈로 컨슈머는 픽업 준비 요청 이후, 배차 완료를 수신할 수도 있습니다. 순서가 보장되지 않는다면 컨슈머 측에서는 거의 동시에 발생한 이벤트에 대해서 어떤 이벤트가 먼저 발생한 것인지 혼란스러워 비즈니스 로직 처리에 문제가 발생할 수 있습니다.

![](https://i.imgur.com/k9NHSRq.png)

따라서 배달의 민족은 주문을 거쳐 배달까지의 과정을 안전하게 처리하기 위해, 순서를 보장해주는 메시지 브로커인 Apache Kafka를 사용합니다.
#### 1. 메세지 발행 순서를 보장해주는 Apache Kafka 
Apache Kafka의 프로듀서는 모든 이벤트를 카프카 브로커에 있는 토픽으로 저장합니다.
주문, 배달, 분석 등 목적에 따라 토픽을 구성할 수 있으며, 하나의 토픽은 병렬처리로 처리량을 높이기 위해 여러 개의 파티션으로 구성됩니다.
![](https://i.imgur.com/igjjClz.png)

하나의 토픽으로 들어온 메시지들은 같은 키를 가진다면 같은 파티션으로 할당되고, 각 파티션은 특정 그룹내 특정 컨슈머에 의해 독점적으로 소비됩니다. 같은 키를 갖는 메시지들은 하나의 파티션의 뒷부분부터 차곡차곡 쌓입니다. 즉, 같은 파티션 내부에 들어간 이벤트들은 같은 서버가 소비하게 되어 이벤트의 순서가 보장됩니다.

따라서 배차 완료 이벤트와 픽업 준비 요청 이벤트가 각각 동일한 주문 ID를 키로 사용한다면, 이 두 이벤트는 같은 파티션에 저장되며 발행 순서가 보장됩니다.
![](https://i.imgur.com/svNGjGZ.png)

이처럼 메시지 공급자가 발행 순서를 보장하기에 거의 비슷한 시점에 발행되는 메시지 동시성 이슈 발생 상황을 줄일 수 있습니다.

---

배달의 민족은 비즈니스 로직을 처리하기 위한 데이터를 MySQL 데이터베이스에 저장한뒤 Kafka로 이벤트를 발행하는 방식으로 데이터와 이벤트를 관리하고 있습니다. 카프카에 문제가 발생할 경우, 데이터베이스에는 변경된 배달상태가 저장되었으나 이벤트는 발행되지 않을 수도 있습니다.

예를 들어 배달 취소가 발생하게 되면 데이터베이스에는 해당 배달은 취소된 상태로 저장될 것입니다. 하지만 이벤트 발행에 실패하게 된다면 컨슈머는 메시지를 수신하지 못해 여전히 배달을 진행할 수 있습니다. 즉, 취소된 배달이 진행되는 문제가 발생할 수 있습니다.

또한, 데이터 베이스 내부 트랜잭션에 실패할 경우 데이터는 롤백되지만, 이벤트는 발송될 수 있고, 메시지 전송 중 문제가 발생하는 경우 메시지 전송 원자성이 보장되지 않을 수 있습니다.

따라서 데이터베이스 트랜잭션과 메시지 큐를 조합하여 데이터 일관성과 메시지 전송의 원자성을 보장하는 패턴인 Transactional Outbox Pattern을 사용합니다.
#### 2. 이벤트 누락을 방지하는 Transactional Outbox Pattern
Transactional Outbox Pattern의 진행 흐름은 아래와 같습니다.

1. 트랜잭션 데이터베이스에 Outbox 테이블을 도입하여, 트랜잭션 완료 시 변경 사항을 기록합니다.
2. Outbox 테이블에 새로운 레코드가 추가될 때마다 변경 사항을 메시지로 전송합니다.



![](https://i.imgur.com/Bj4Jp1z.png)

위와 같은 패턴을 구현하기 위해  Debezium에서 지원하는 MySQL 카프카 커넥터를 이용합니다.
데이터베이스의 변경 사항을 감지하고 이벤트 스트림으로 변환하는 오픈 소스 라이브러리인 Debezium은  데이터베이스의 기록인 binlog의 변경 사항을 cdc하여 읽은 뒤, 설정한 토픽으로 메시지를 발행합니다.

만약, 메시지 발행에 실패하면 Outbox 테이블의 데이터도 롤백되기 때문에 데이터베이스의 변경과 메시지 발행이 하나의 트랜잭션으로 관리됩니다.

 Debezium에서 메시지 발행에 사용되는 MySQL source connector의 처리 속도가 테이블에 데이터가 쌓이는 속도보다 느리다면, 메시지 지연이 발생할 수 있습니다. 처리량을 높이기 위해 토픽별로 outbox 테이블을 분리하여 만들고, 각 outbox 테이블은 식별자 기반으로 N개의 테이블로 구성하였습니다.
 각 테이블에 커넥터를 연결하여 한 커넥터가 처리하는 양을 분산하였고, 같은 키는 같은 테이블에 저장되며 한 테이블은 하나의 커텍터를 사용하기에 같은 키에서는 메시지 발행 순서가 보장됩니다.
 
![](https://i.imgur.com/BeX186T.png)

---
배달의 민족은 주문 이벤트를 받아 배달 프로세스를 관리만 하는 것뿐만 아니라, 발행한 이벤트를 기반으로 분석에 적합한 형태로 가공하여 데이터를 제공합니다. 
![](https://i.imgur.com/5z2YWSy.png)
배달 정보를 집계하여 배달 상황을 파악하는 예시를 들어보겠습니다. 실시간 혹은 준실시간에 해당하는 데이터를 조회하여 배달현황을 파악하기 위해 데이터는 전처리 단계와 스트림 연결과정을 거칩니다.
#### 3.  대량 데이터를 실시간으로 처리하기 위한 Apache Kafka Streams

우선 라이더의 gps를 행정동으로 전처리 한뒤 새로운 이벤트를 발행합니다.
![](https://i.imgur.com/vbJhHaG.png)

확장된 배달 스트림과 라이더 스트림을 조인하여 라이더 스냅샷을 만듭니다.  
![](https://i.imgur.com/SGCzThd.png)

라이더 스냅샷 스트림을 Kafka Streams를 통해 행정동 단위로 데이터를 집계합니다. 이 데이터는 키로 행정동을, 값으로 배달 상태별 개수를 사용하여 상태 저장소에 분산 저장됩니다. 이를 통해 각 행정동에서의 배달 상태를 실시간으로 모니터링할 수 있습니다
![](https://i.imgur.com/rvbqbsi.png)

또한, 배달의 이벤트( 생성, 배차, 픽업, 완료 )를 하나하나 보는 것이 아닌 배달 건별로 정리된 정보를 확인하고 싶은 경우엔 한 배달건에 대해 발생한 여러 이벤트를 하나로 모아 완료된 배달 건의 요약된 종합 정보를 Redis에 임시 저장소에서 삭제한 뒤, 새로운 배달통합이벤트를 분석 토픽에 발행합니다. S3 싱크 커넥터를 사용하여 분석토픽에 들어간 이벤트는 AWS S3 객체저장소에 보내 영구 저장됩니다. S3 객체저장소에 저장된 데이터는 AWS Athena 를 사용해 비즈니스 서비스 저장소에 부하를 주지 않고 오래된 기록까지 조회할 수 있습니다.

![](https://i.imgur.com/Njn13P8.png)

---
### 정리
배달의 민족 딜리버리팀은 메시지 처리의 순서를 보장하고 데이터 누락을 방지하기 위해 여러 기술을 통합적으로 활용합니다. 메시지 처리의 순서를 보장하기 위해 메시지 브로커인 Kafka 를 사용하고, 순서를 보장하며 누락 없이 메시지를 발행하기 위해 MySQL Source Connector와 Transactional Outbox Pattern을 사용합니다. 또한 Kafka Streams을 사용하여 실시간에 가까운 데이터 스트리밍 분석을 수행하고, 분석용 데이터는 AWS S3와 같은 다양한 클라우드 기반 스토리지 옵션에 저장됩니다.

---
Q ) 데이터베이스가 아닌 Kafka에 문제가 생겼을 경우 이벤트 발행이 되지 않을 수도 있다는 점을 지적하며, Transactional Outbox Pattern을 사용한다고 했다. 데이터 베이스 변화를 추적하는 방법인건가?
- 변경 데이터 캡처 (Change Data Capture, CDC)
데이터베이스의 변화를 추적하고 이러한 변화를 이벤트로 Kafka에 전송한다.
- 이벤트 소싱
이벤트(메시지)가 모든 상태 변경의 중심이 됩니다. 즉, 이벤트가 발생하고 Kafka에 기록되면, 이 이벤트를 구독하고 있는 다양한 시스템이나 데이터베이스가 이를 소비하여 자신의 상태를 갱신한다.
---
### 초안
저희는 배달의 민족의 주력 서비스인 배달 시스템에 초점을 맞추어 데이터 파이프라인을 조사해 보았습니다.

배달의 민족 딜리버리 서비스는 고객의 주문 생성부터 음식 전달까지의 전 과정을 실시간으로 처리합니다.
고객이 주문을 생성하면, 업소는 이를 수락하고 시스템은 근처의 가장 적합한 배달원을 계산하여 배차를 권유합니다. 배달원이 배차를 수락하면, 업소에는 배달원의 도착 예정 시간이 알려지고, 배달원은 업소에서 음식을 픽업합니다. 이후, 배달원은 고객에게 도착할 시간을 실시간으로 트래킹하며, 최종적으로 고객에게 음식을 전달합니다.

이러한 각 단계는 데이터 파이프라인을 통해 실시간으로 관리되며, 다음과 같은 특징을 가진 데이터를 처리합니다.
- 고볼륨 : 매일 수백만 건의 주문 데이터를 처리합니다.
- 고속 처리 요구 : 주문과 배달의 실시간 처리가 필요하며, 매우 빠른 처리 속도를 요구 합니다.
- 이벤트 기반 : 주문은 하나의 이벤트로 처리되며, 이벤트들은 실시간으로 추척, 처리 되어야 합니다.
### Apache Kafka 
배달의 민족은 이벤트 기반 아키텍쳐를 적용하며 **이벤트의 순서**를 중요하게 여겼고, 이벤트를 발행하기 위해 순서를 보장해주는 메시지 브로커인 Apache Kafka 를 사용하였습니다. 
![](https://i.imgur.com/4f4sALA.png)

Kafka의 프로듀서는 모든 이벤트를 카프카 브로커에 있는 토픽으로 저장됩니다. 
![](https://i.imgur.com/igjjClz.png)

이벤트에 키가 존재할 때 메시지는 파티션과 1:1 매핑되고 같은 키를 갖는 메시지들은 한 파티션 내부에서 뒤부터 차곡차곡 쌓입니다. 즉, 같은 파티션 내부에 들어간 이벤트들은 그 순서가 보장됩니다.
![](https://i.imgur.com/svNGjGZ.png)

![](https://i.imgur.com/x9zoevD.png)

예를 들어 배달 번호를 기반으로 이벤트를 발행하므로써 배달의 순서를 보장할 수 있습니다.
![](https://i.imgur.com/1zyzMyg.png)

과거 배달의 민족은 주문 이벤트가 들어오면 이를 데이터베이스에 저장한 뒤, 설정된 시간에 따라 배치 스케쥴이 돌면서 데이터베이스로부터 데이터를 조회하고, 데이터를 가공한 뒤 별도의 데이터 베이스에 저장하는 방식으로 주문 데이터를 처리했었습니다.
![](https://i.imgur.com/viujju8.png)

하지만, 서비스 규모가 커지며 하루에 100만 건 이상의 주문을 처리해야 하는 상황, 식사 시간이나 특정 이벤트 기간 동안엔 주문량 변동이 커지는 상황 때문에 배치 처리 방식으로는 더 이상 대응하기 어려웠습니다. 이에 배달의 민족은 대량 데이터를 실시간으로 처리하기 위해 Apache Kafka Streams를 도입했습니다.

### Apache Kafka Streams
Apache Kafka Streams는 분산된 방식으로 대규모 데이터를 스트림(stream)으로 처리할 수 있도록 설계된 라이브러리입니다. 

예를 들어 배달 타입별로 배달을 집계하고자 할 때, 스트림 프로세서 즉 카프카 컨슈머는 배달이라는 토픽을 인풋으로 받고 분산 처리된 결과를 상태 저장소에 저장합니다. 이 스트림 프로세서의 구현은 개발자가 담당합니다.
또한, 상태 저장소에 저장된 데이터는 다른 토픽으로도 전송되어 관리될 수 있으며, 이 데이터는 다른 비즈니스 로직에서 활용될 수 있습니다.
![](https://i.imgur.com/gDi6nvM.png)

다른 예로 지역별 배달현황을 집계하고자 할 때, 활용할 수 있는 도메인 이벤트론 배달 이벤트와 라이더 이벤트가 있습니다.
cf ) 도메인 이벤트는 도메인 모델 내에서 발생하는 중요한 사건을 나타내는 개념입니다.

1. 배달 이벤트
배달 생성, 배차 확정, 라이더 픽업, 고객에게 전달 되는 등의 행위가 발생할 때 이벤트가 발행됩니다.
이벤트에 포함되는 데이터는 이 행위에 영향을 받은 속성들입니다.

2. 라이더 이벤트
운행 시작, 운행 중, 운행 종료등의 행위가 발생할 때 이벤트가 발행됩니다.
![](https://i.imgur.com/EmWdObo.png)

지역별 배달현황을 집계하고자 할 때 세가지 요구사항을 충족해야 합니다.
![](https://i.imgur.com/Gr5W711.png)

우선 라이더의 gps를 행정동으로 전처리 한뒤 새로운 이벤트를 발행합니다.
![](https://i.imgur.com/vbJhHaG.png)

확장된 배달 스트림과 라이더 스트림을 조인하여 라이더 스냅샷을 만듭니다.  
![](https://i.imgur.com/SGCzThd.png)

라이더 스냅샷 스트림을 받아들이고 kafka streams를 통해 행정동 단위로 집계가 되고 여러 인스턴스에 분산되어 저장됩니다.
![](https://i.imgur.com/rvbqbsi.png)

- Apache Kafka Streams는 토폴로지를 구성합니다.
![](https://i.imgur.com/9uw0ve9.png)
##### 소스 프로세서 : Kafka 토픽으로부터 데이터를 읽어옵니다.
##### 프로세서 : 데이터를 변환, 필터링, 집계하는 등의 작업을 수행합니다. -> 개발자가 작업합니다.
##### 싱크 프로세서: 처리된 데이터를 다시 Kafka 토픽에 쓰거나, 다른 시스템으로 내보냅니다.

실시간으로 들어오는 데이터를 처리하는 방식 중 상태 기반 분산 프로세스를 개발하는 것은 매우 어렵습니다.
streams는 로컬에 rocksDB를 사용해서 상태를 저장하고, 이 상태에 대한 변경을 변경 로그에 저장하기에 장애 복구가 가능합니다.
#### 정리하자면
1. 배달과 라이더 이벤트를 적절히 전처리하여 라이더 스냅샷을 만듭니다. 
2. 라이더 스냅샷 스트림으로 스트림처리를 하면 상태 저장소에 분산되어 저장됩니다.
3. 단일 백업 저장소를 둬서 시스템 장애, 배포, 인스턴스 추가/ 삭제와 같은 비정상 상태일때도 데이터를 이용할 수 있게 합니다.
4. 수집된 데이터는 배달 상태와 라이더의 위치를 실시간으로 모니터링하거나, 배달 경로 최적화하는 등 여러 비즈니스 로직에 활용된다.
![](https://i.imgur.com/W2fq1Ck.png)


---