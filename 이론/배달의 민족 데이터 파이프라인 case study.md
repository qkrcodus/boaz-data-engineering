#### 출처 : 우아콘2023 , 데브원영

저희는 배달의 민족의 주력 서비스인 배달 시스템에 초점을 맞추어 데이터 파이프라인을 조사해 보았습니다.

배달의 민족 딜리버리 서비스는 고객의 주문 생성부터 최종 음식 전달까지의 전 과정을 실시간으로 처리합니다.
고객이 주문을 생성하면, 업소는 이를 수락하고 시스템은 근처의 가장 적합한 배달원을 계산하여 배차를 권유합니다. 배달원이 배차를 수락하면, 업소에는 배달원의 도착 예정 시간이 알려지고, 배달원은 업소에서 음식을 픽업합니다. 이후, 배달원은 고객에게 도착할 시간을 실시간으로 트래킹하며, 최종적으로 고객에게 음식을 전달합니다.

이러한 각 단계는 데이터 파이프라인을 통해 실시간으로 관리되며, 다음과 같은 특징을 가진 데이터를 처리합니다.
- 고볼륨 : 매일 수백만 건의 주문 데이터를 처리합니다.
- 고속 처리 요구 : 주문과 배달의 실시간 처리가 필요하며, 매우 빠른 처리 속도를 요구 합니다.
- 이벤트 기반 : 주문은 하나의 이벤트로 처리되며, 이벤트들은 실시간으로 추척, 처리 되어야 합니다.

### Apache Kafka 
배달의 민족은 이벤트 기반 아키텍쳐를 적용하며 **이벤트의 순서**를 중요하게 여겼고, 이벤트를 발행하기 위해 순서를 보장해주는 메시지 브로커인 Apache Kafka 를 사용하였습니다. 
![](https://i.imgur.com/4f4sALA.png)

Kafka의 프로듀서는 모든 이벤트를 카프카 브로커에 전송하고 이들은 토픽으로 저장됩니다. 
![](https://i.imgur.com/igjjClz.png)

키가 존재할 때 메시지는 파티션과 1:1 매핑되고 메시지는 뒤에서부터 차곡차곡 쌓이기에 토픽 안 같은 파티션 내부에 들어간 이벤트들은 그 순서가 보장됩니다.
![](https://i.imgur.com/svNGjGZ.png)
![](https://i.imgur.com/x9zoevD.png)

예를 들어 배달 번호를 기반으로 이벤트를 발행하므로써 배달의 순서를 보장할 수 있습니다.
![](https://i.imgur.com/1zyzMyg.png)

과거 배달의 민족은 주문 이벤트가 들어오면 이를 데이터베이스에 저장한 뒤, 설정된 시간에 따라 배치 스케쥴이 돌면서 데이터베이스로부터 데이터를 조회하고, 데이터를 가공한 뒤 별도의 데이터 베이스에 저장하는 배치 방식으로 주문 데이터를 처리했었습니다.
![](https://i.imgur.com/viujju8.png)

하지만, 하루에 100만 건 이상의 주문을 처리해야 하는 상황과, 식사 시간이나 특정 이벤트 기간 동안엔 주문량 변동이 크기 때문에 배치 처리 방식으로는 대응하기 어려웠습니다. 이에 배달의 민족은 대량 데이터를 실시간으로 처리하기 위해 Apache Kafka Streams를 도입했습니다.

### Apache Kafka Streams
Apache Kafka Streams는 분산된 방식으로 대규모 데이터를 스트림(stream)으로 처리할 수 있도록 설계된 라이브러리입니다. 

예를 들어 배달 타입별로 배달을 집계하고자 할 때, 스트림 프로세서 즉 카프카 컨슈머는 배달이라는 토픽을 인풋으로 받고 처리된 결과를 상태 저장소에 저장합니다. 저장된 값들은 별도의 토픽으로도 관리 가능합니다.
![](https://i.imgur.com/gDi6nvM.png)

라이더의 gps를 행정동으로 전처리 한뒤 새로운 이벤트를 발행합니다.
![](https://i.imgur.com/vbJhHaG.png)

확장된 배달 스트림과 라이더 스트림을 조인하여 라이더 스냅샷을 만듭니다.  
![](https://i.imgur.com/SGCzThd.png)

라이더 스냅샷 스트림을 받아들이고 kafka streams를 통해 행정동 단위로 집계가 되고 여러 인스턴스에 분산되어 저장됩니다.
![](https://i.imgur.com/rvbqbsi.png)

- Apache Kafka Streams는 토폴로지를 구성합니다.
![](https://i.imgur.com/9uw0ve9.png)
##### 소스 프로세서 : Kafka 토픽으로부터 데이터를 읽어옵니다.
##### 프로세서 : 데이터를 변환, 필터링, 집계하는 등의 작업을 수행합니다. -> 개발자가 작업합니다.
##### 싱크 프로세서: 처리된 데이터를 다시 Kafka 토픽에 쓰거나, 다른 시스템으로 내보냅니다.

실시간으로 들어오는 데이터를 처리하는 방식 중 상태 기반 분산 프로세스를 개발하는 것은 매우 어렵다. 
streams는 로컬에 rocksDB를 사용해서 상태를 저장하고, 이 상태에 대한 변경을 변경 로그에 저장하기에 장애 복구가 가능하다. 
#### 정리하자면
1. 배달과 라이더 이벤트를 적절히 전처리하여 라이더 스냅샷을 만듭니다. 
2. 라이더 스냅샷 스트림으로 스트림처리를 하면 상태 저장소에 분산되어 저장됩니다.
3. 단일 백업 저장소를 둬서 시스템 장애, 배포, 인스턴스 추가/ 삭제와 같은 비정상 상태일때도 데이터를 이용할 수 있게 합니다.
4. 수집된 데이터는 배달 상태와 라이더의 위치를 실시간으로 모니터링하거나, 배달 경로 최적화하는 등 여러 비즈니스 로직에 활용된다.
![](https://i.imgur.com/W2fq1Ck.png)


