#### 출처 : 우아콘2023 , 데브원영 , 우아한 기술 블로그
를 토대로 이해한 내용을 정리했습니다.
### 팀원 : 유승재, 정준경, 박채연

# 1. 개요

저희는 배달의 민족 주력 서비스인 딜리버리 서비스의 배달 프로세스 관련 운영 파이프라인과 분석 파이프라인을 조사했습니다.

운영 파이프라인에서 사용되는 Kafka 와 Transactional Outbox Pattern 그리고 분석 파이프라인에서 사용되는 Kafka Streams 에 대해 소개하고, 파이프라인의 수집과 처리 부분으로 나누어 살펴보겠습니다.

## 1.1 서비스 소개
![](https://i.imgur.com/PMvWEBS.png)
분산서버 구조

- 배달의 민족 딜리버리 서비스는 고객의 주문 생성부터 최종 음식 전달까지 전 과정을 실시간으로 처리
- 분산 이벤트 기반 아키텍처를 사용하여, 주문과 배달 프로세스를 담당하는 주문/배달 서버와, 발행된 이벤트를 분석하는 분석 서버로 구성
- 각 서버 그룹은 여러 대의 서버로 구성하여 처리량과 성능을 향상

# 2. 운영 데이터 파이프라인

## 2.1 Kafka
![](https://i.imgur.com/ju2tl2H.png)

### 배경 설명

![이벤트 및 배달 상태에 따른 배달 프로세스](https://i.imgur.com/k9NHSRq.png)

이벤트 및 배달 상태에 따른 배달 프로세스

이벤트 기반 시스템에서 프로듀서는 이벤트를 생성하고 발행

- 생성 : 사용자의 행동이나 시스템의 상태 변화 등, 데이터 원천(Source)에서 발생하는 신호나 데이터를 바탕으로 이벤트 생성
- 발행 : 노란색으로 표시된 배달 상태는 배달 생성, 배차 완료, 픽업 완료, 전달 완료 순으로 배달 상태를 변경 후, 배달 상태 변화에 따라 이벤트 발행

### 문제 상황

<aside> 📌

배달 프로세스에서 배차 완료와 픽업 준비 요청 이벤트 거의 동시에 발생할 수 있습니다.

비록 프로듀서가 배차 완료 → 픽업 준비 요청 순으로 이벤트를 발행 했어도 네트워크 등의 이슈로 컨슈머는 픽업 준비 요청 이후에 배차 완료를 수신할 수도 있습니다.

</aside>

- 이벤트 간 발행 순서가 보장되지 않는다면 컨슈머 측에서는 거의 동시에 발생한 이벤트의 처리 순서가 역전

### 해결 방법

- Apache Kafka를 사용하여 주문부터 배달까지의 프로세스를 관리
- Kafka는 각 파티션 내에서 메시지의 순서를 보장함 ⇒ 컨슈머가 이벤트를 발행된 순서대로 처리

### 2.1.1 Apache Kafka 기술 설명

- 토픽 저장 및 파티션 구성
    
    - Apache Kafka의 프로듀서는 모든 이벤트를 카프카 브로커에 있는 토픽으로 저장
    - 하나의 토픽의 처리량을 높이기 위해 여러 개의 파티션으로 구성
    - 하나의 토픽으로 들어온 메시지들은 같은 키를 가진다면 같은 파티션으로 할당
    - 각 파티션은 특정 그룹내 특정 컨슈머에 의해 독점적으로 소비
    
    ![](https://i.imgur.com/igjjClz.png)
    
- 예시
    
    ![RDjnaVZ.png](https://i.imgur.com/RDjnaVZ.png)
    clicklog : 토픽, {”1” ,”2”}: 키, buy review: 메시지
    
- 파티션 내부
    
    - 같은 키를 갖는 메시지들은 하나의 파티션의 뒷부분부터 적재
        
        ⇒ 같은 파티션 내부에 들어간 이벤트들은 하나의 컨슈머가 소비
        
        ⇒ 이벤트의 순서 보장
        

![](https://i.imgur.com/svNGjGZ.png)

### 2.1.2 메시지 순서가 보장되는 이유

배차 완료와 픽업 준비 요청 이벤트 거의 동시에 발생하는 경우,

배차 완료 이벤트와 픽업 준비 요청 이벤트가 각각 동일한 주문 ID를 키로 사용 ⇒ 두 이벤트는 **같은 파티션**에 저장되며 **하나의 컨슈머**에 의해 처리 ⇒ 이벤트의 순서 보장

## 2.2 Transactional Outbox Pattern

### 배경 설명

<aside>

데이터 → MySQL 에 저장 → Kafka를 통한 이벤트 발행

</aside>

배달의 민족은 비즈니스 로직을 처리하기 위한 데이터를 **MySQL** 데이터베이스에 저장한 뒤, **Kafka**를 통해 이벤트를 발행하는 방식으로 데이터와 이벤트를 관리하고 있습니다.

### 문제 상황

<aside> 📌

카프카에 문제가 발생할 경우, 데이터베이스에는 변경된 배달 상태가 저장 되었으나 이벤트는 발행되지 않을 수도 있습니다.

</aside>

- 배달 취소가 발생하게 되면 데이터베이스에는 해당 배달은 취소된 상태로 저장
- **이벤트 발행에 실패** ⇒ 컨슈머는 메시지를 수신 X ⇒ 취소된 배달이 진행되는 문제 발생

### 해결 방법: Transactional Outbox Pattern

- 데이터베이스의 트랜잭션과 메시지 큐를 통합 ⇒ 모든 데이터베이스 작업과 메시지 발행을 하나의 트랜잭션 내에서 완료 ⇒ 데이터 일관성과 메시지 전송의 원자성을 보장

### 2.2.1 Transactional Outbox Pattern 기술 설명

![](https://i.imgur.com/Bj4Jp1z.png)

**Outbox 테이블**

- 데이터베이스 내에서 트랜잭션이 완료되는 순간에 발생하는 변경 사항을 기록
- 새로운 레코드가 추가 될 때마다 데이터베이스 변경 사항이 메시지 형태로 전송

**Debezium**

- 위의 패턴을 구현하기 위해 사용
- 데이터베이스의 변경 사항을 감지하고 이벤트 스트림으로 변환하는 오픈 소스 라이브러리

<aside> 💡

마찬가지로 **메시지 발생 실패** 경우도 존재

</aside>

### 2.2.2 메시지 정합성이 보장되는 이유

- 데이터베이스의 변경과 메시지 발행이 하나의 트랜잭션으로 관리 ⇒ 메시지 발행에 실패하면 Outbox 테이블의 데이터도 롤백 ⇒ 프로듀서에서 발행되는 메시지들이 안전하게 처리

### 2.2.3 Transactional Outbox Pattern 예시
![](https://i.imgur.com/LhdJW54.png)

1. 주문 이벤트를 배달 이벤트로 변환 후 저장
2. OUTBOX table에 로그 테일링 기법을 적용
    1. 트랜잭션의 성공 내역을 binlog 기록하고, 기록을 순서대로 읽어가도록 동작
    2. 메시지 발행에 실패하면 아웃 박스 테이블의 데이터도 롤백되기 때문에 하나의 트랜잭션으로 데이터 정합성을 관리
3. 처리량 증강
    1. 토픽 별로 outbox 테이블 분리
    2. 테이블과 MySQL Kafka Connecter 1:1 연결 ⇒ 커넥터의 데이터 처리량 분산

### 2.2.4 메시지 발행 순서 보장

- 하나의 토픽에 대응하는 하나의 Outbox 테이블을 설정하여, 해당 테이블의 데이터는 동일한 커넥터를 통해 관리
- 데이터베이스의 변경 사항이 Kafka 토픽으로 순차적으로 전송 ⇒ 하나의 토픽의 메시지 발행 순서의 일관성을 보장

# 3. 분석 데이터 파이프라인

## 3.1 Apache Kafka Streams

### 배경 설명 및 문제 상황

![](https://i.imgur.com/viujju8.png)

배치를 사용하여 분석을 위한 데이터를 제공할 수도 있지만, 서비스 규모가 커지며 하루에 100만 건 이상의 주문을 처리해야 하는 상황이 됐고, 특히 식사 시간이나 특정 이벤트 기간과 같이 주문량 변동이 커지는 경우엔 일정 주기로 배치를 수행 ⇒ 실시간 데이터 반영이 어려움

### 해결 방법

카프카 스트림즈를 활용하여 실시간 혹은 준실시간에 해당하는 데이터를 조회하여 배달현황을 파악하고 서비스에 반영

이때, 원본 토픽과 분석용 토픽을 분리하여 사용

- 배달 이벤트를 수신한 후 전처리 과정을 거쳐, 조회하기 편한 형태로 가공하여 분석 토픽으로 이벤트를 재 발행
- 서비스(=원본) 토픽과 분석용 토픽은 서로 다른 데이터 처리량과 리소스가 필요 ⇒ 토픽과 서버를 분리하여 특성에 맞는 리소스를 사용하고 조정 가능하도록 구성

**기대효과**

- 현재 배달 상황을 파악하고 대응
- 실시간 이상 탐지 자동화 ⇒ 서비스 장애 파악 ⇒ 주문 유입을 최소화하여 장애 범위 최소화

### Apache Kafka Streams: 행정동 별 배달 상태 모니터링

1. **이벤트 발행**
    
    ![](https://i.imgur.com/vbJhHaG.png)
    
    : 라이더의 gps를 행정동으로 전처리 후, 새로운 이벤트를 발행
    
2. **스냅샷 스트림 생성**
    
    ![](https://i.imgur.com/SGCzThd.png)
    
    확장된 배달 스트림과 라이더 스트림을 조인하여 라이더 스냅샷 생성
    
3. **Kafka Streams를 통한 데이터 집계 및 모니터링**
    
    ![](https://i.imgur.com/rvbqbsi.png)
    
    - 라이더 스냅샷 스트림을 Kafka Streams를 통해 행정동 단위로 데이터를 집계
    - 데이터는 키로 행정동을, 값으로 배달 상태 별 개수를 사용하여 상태 저장소에 분산 저장
    
    ⇒ 각 행정동에서의 배달 상태를 실시간으로 모니터링
    

## 3.2 클라우드 서비스

![](https://i.imgur.com/taBiZ5W.png)

### 3.2.1 데이터 수집 및 저장

- 원본 배달 토픽에서 배달 생성 이벤트를 수신 후, Redis에 주요한 주문과 배달 정보를 저장

### 3.2.2 데이터 처리

- 완료된 배달은 Redis에서 삭제하고, 의미 있는 정보로 구성한 새로운 배달 통합이벤트를 분석 토픽에 발행

### 3.2.3 데이터 로드

- 분석 토픽에 발행한 배달 이벤트를 스트림즈 애플리케이션이나 S3에 로드
    
- 스트림즈 애플리케이션 또는 그라파나 대시보드를 사용해 모니터링
    
    - 대시보드 시각화 예시
        ![BDF5wBX.png](https://i.imgur.com/BDF5wBX.png)
        
- S3: 배치 분석
    - S3 객체저장소에 저장된 데이터는 [AWS Athena](https://aws.amazon.com/ko/athena/)를 사용해 비즈니스 서비스 저장소에 부하를 주지 않고 오래된 기록까지 조회

# 4. 정리

배달의 민족은 이벤트 기반 아키텍처를 사용하며, 서비스의 신뢰성을 높이기 위해 여러 기술과 통합하여 운영됩니다.

- 메시지 발행 순서와 처리 순서를 보장하기 위해 Kafka를 사용
- 메시지 정합성과 발행 순서 보장하기 위해 Transactional Outbox Pattern을 사용
- 실시간 데이터 분석을 위해 Kafka Streams를 적용하며, 분석된 데이터를 장기적으로 저장하고 활용하기 위해 다양한 클라우드 기반 데이터 저장소를 활용
---
Q ) 데이터베이스가 아닌 Kafka에 문제가 생겼을 경우 이벤트 발행이 되지 않을 수도 있다는 점을 지적하며, Transactional Outbox Pattern을 사용한다고 했다. 데이터 베이스 변화를 어떻게 추적하는가?

A )변경 데이터 캡처 (Change Data Capture, CDC)
- 데이터베이스의 변화를 추적하고 이러한 변화를 이벤트로 Kafka에 전송한다. 
- 데이터가 기록되자마자 변경 내용을 스트림으로 제공하는데 유용하다.
- 기본키의 현재 값은 전적으로 기본키의 가장 최신 이벤트로 결정된다.
- 같은 키의 이벤트는 이전 이벤트로 덮어 쓰는것이 가능하기에 로그 캠팩션이 가능하다.

즉 카프카는 CDC를 사용하며 로그 컴팩션이 가능하다. 

cf) 로그 컴팩션 : 주기적으로 같은 키의 로그 레코드를 찾아 중복을 제거하고 각 키에 대해 가장 최근에 갱신된 내용만 유지해줌