### 29
회사는 ==UDP 연결을 사용하는 VoIP(Voice over Internet Protocol) 서비스==를 제공합니다. 이 서비스는 Auto Scaling 그룹에서 실행되는 Amazon EC2 인스턴스로 구성됩니다. 회사는 ==여러 AWS 리전에 배포==하고 있습니다. 회사는 ==지연 시간이 가장 짧은 리전으로 사용자를 라우팅==해야 합니다. 이 회사는 또한 ==지역 간 자동 장애 조치==가 필요합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

==A. NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 리전에서 NLB 를 AWS Global Accelerator 엔드포인트로 사용합니다. ==
B. ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 리전에서 ALB 를 AWS Global Accelerator 엔드포인트로 사용합니다. 
C. NLB(Network Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 NLB 의 별칭을 가리키는 Amazon Route 53 지연 시간 레코드를 생성합니다. 지연 시간 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 생성합니다. 
D. ALB(Application Load Balancer) 및 연결된 대상 그룹을 배포합니다. 대상 그룹을 Auto Scaling 그룹과 연결합니다. 각 ALB 의 별칭을 가리키는 Amazon Route 53 가중치 레코드를 생성합니다. 가중 레코드를 오리진으로 사용하는 Amazon CloudFront 배포를 배포합니다.

---
##### Network Load Balancer (NLB)
네트워크 : network layer에서 작동 ( TCP, UDP 프로토콜 처리 )
로드 밸린서 : 트래픽 균등 분산
UDP 통신 : TCP 와 다르게 비연결적 통신 방식 지원하므로 연결에 드는 시간을 절약, 따라서 실시간 프로그램 (voip, 게임 서버)에 사용
##### Application Load Balancer (ALB)
어플리케이션 : application layer에서 작동 ( HTTP, HTTPS 프로토콜 처리 )
##### AWS Global Accelerator
억셀러레이터 : 가장 반응이 빠른 즉 가장 가까운 리전으로 트래픽을 빠르게 라우팅하고, 장애 발생시 빠르게 자동으로 다른 건강한 리전으로 전환

고정 IP 주소를 사용하기에 
AWS Global Accelerator를 사용하면 DNS 가 Global Accelerator 에 할당된 고정 IP 주소를 반환하기에 DNS 변경 없이 트래픽을 빠르게 다른 리전으로 리디렉션 가능하게 한다.
##### Amazon Route 53
라우트 : dns 서비스 , 도메인 네임 -> ip 주소 -> 연결된 서버로 트래픽이 라우팅되도록 해준다
##### Amazon CloudFront
프론트 : cdn 서비스 사용자와 가장 가까운 위치(전선)에서 신속하게 데이터를 제공한다
정적 컨텐츠를 웹 계층에 따로 보관 , 캐시하여 빠르게 제공

---

여러 리전에 걸쳐있고, 트래픽을 관리 한다 => 로드밸린서 필요
udp 프로토콜 사용하는 서비스 제공 => NLB
트래픽을 최적 경로로 라우팅, 지역간 자동 장애 조치 => AWS Global Accelerator

---
### 30
개발 팀은 ==성능 개선 도우미가 활성화된 MySQL DB 인스턴스용 범용 Amazon RDS ==에서 매월 리소스 집약적 테스트를 실행합니다. 테스트는 ==한 달에 한 번== ==48 시간== 동안 지속되며 데이터베이스를 사용하는 유일한 프로세스입니다. 팀은 DB 인스턴스의 ===컴퓨팅 및 메모리 속성을 줄이지 않고 테스트 실행 비용을 줄이려고 합니다.== 어떤 솔루션이 이러한 요구 사항을 가장 비용 효율적으로 충족합니까?

A. 테스트가 완료되면 ==DB 인스턴스를 중지==합니다. 필요한 경우 DB 인스턴스를 다시 시작합니다. 
B. DB 인스턴스와 함께 Auto Scaling 정책을 사용하여 테스트가 완료되면 자동으로 확장합니다. 
==C. 테스트가 완료되면 스냅샷을 만듭니다. DB 인스턴스를 종료하고 필요한 경우 스냅샷을 복원합니다. ==
D. 테스트가 완료되면 DB 인스턴스를 저용량 인스턴스로 수정합니다. 필요한 경우 DB 인스턴스를 다시 수정합니다.

---

#### 확실히 아닌 선지
B ) Auto Scaling (자동적 스케일링) 정책 => 변동적인 트래픽에 사용 , 서버 인스턴스 수를 자동적으로 조정한다

D ) 저용량 인스턴스로 수정 => 컴퓨팅 메모리 속성을 줄인다

#### 애매한 선지
A ) DB 인스턴스를 중지

![](https://i.imgur.com/9OAR6CN.png)

따라서 필요할 때 빠르게 재개해야 할 경우에 적합

RDS 인스턴스는 최대 7일 동안만 중지할 수 있으며, 이후에는 자동으로 다시 시작되기에 인스턴스를 중지하는 것보다 종료하는게 더 적합

C ) 스냅샷 후 DB 인스턴스를 종료

장기적으로 DB 인스턴스를 사용하지 않을 때 적합

재시작시 새로운 인스턴스를 생성해야하기에 시간과 비용이 걸리지만 한 달 한 번 테스트 한다면 적합

---
### 31
AWS 에서 웹 애플리케이션을 호스팅하는 회사는 모든 Amazon EC2 인스턴스를 보장하기를 원합니다. Amazon RDS DB 인스턴스. Amazon Redshift 클러스터는 태그로 구성됩니다. 회사는 ==이 검사를 구성하고 운영하는 노력을 최소화==하기를 원합니다. 솔루션 설계자는 이를 달성하기 위해 무엇을 해야 합니까?

==A. AWS Config 규칙을 사용하여 적절하게 태그가 지정되지 않은 리소스를 정의하고 감지합니다. ==
B. 비용 탐색기를 사용하여 제대로 태그가 지정되지 않은 리소스를 표시합니다. 해당 리소스에 수동으로 태그를 지정합니다. 
C. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. EC2 인스턴스에서 주기적으로 코드를 실행합니다. 
D. 적절한 태그 할당을 위해 모든 리소스를 확인하는 API 호출을 작성합니다. Amazon CloudWatch 를 통해 AWS Lambda 함수를 예약하여 코드를 주기적으로 실행합니다.

---

태그가 적절히 관리되고 있는지를 자동으로 확인하고, 이 과정에서 수동 작업이나 개입을 최소화하려고 한다

b ) 수동으로 태그 지정

c ) API 호출을 작성합니다. EC2 인스턴스에서 주기적으로 코드를 실행

d ) API 호출을 작성 , AWS Lambda 함수도 작성

⇒ 수동 작업이거나 개발자가 직접 코드 작성해야하는 번거로움

### AWS Config

별도의 인프라 구성 없이도 태그의 일관성과 정확성을 보장할 수 있도록 설계된 툴

---
### 32
개발 팀은 다른 팀이 액세스할 웹사이트를 호스팅해야 합니다. 웹사이트 콘텐츠는 ==HTML, CSS, 클라이언트 측 JavaScript== 및 이미지로 구성됩니다. 웹 사이트 호스팅에 ==가장 비용 효율적인 ==방법은 무엇입니까? 

A. 웹 사이트를 컨테이너화하고 AWS Fargate 에서 호스팅합니다. 
==B. Amazon S3 버킷을 생성하고 거기에서 웹 사이트를 호스팅합니다. ==
C. Amazon EC2 인스턴스에 웹 서버를 배포하여 웹 사이트를 호스팅합니다. 
D. Express.js 프레임워크를 사용하는 AWS Lambda 대상으로 Application Load Balancer 를 구성합니다.

---

HTML, CSS, 클라이언트 측 JavaScript => 클라이언트 요청 전에 이미 생성된 정적 콘텐츠 ( 클라이언트는 필요에 따라 서버와 통신하기도 한다. ajax)
##### AWS Fargate
멀리 있어도 문을 통해 도움을 준다
어플리케이션들을 담은 각 컨테이너를 자동으로 스케일링하고 관리 해줌
트래픽 따라 자동으로 리소소를 축소하거나 확대도 해주고
컨테이너화된 환경에서 자동 배포를 가능하게 해줘 msa를 도와줌
##### Amazon S3 (Simple Storage Service)
간단하게 저렴하게 정적 파일을 저장
##### Amazon EC2 (Elastic Compute Cloud)
elastic 유연한 동적 어플리케이션 ( 사용자 요구 따라 탄력적으로 컴퓨팅 자원을 확장하거나 축소 가능하다), 고도로 맞춤화된 서버 환경이 필요한 경우

Express.js와 같은 Node.js 프레임워크 => 서버리스 환경이 필요한 경우

--- 
### 33
회사는 AWS 에서 온라인 마켓플레이스 웹 애플리케이션을 실행합니다. 이 애플리케이션은 ==피크 시간에 수십만 명의 사용자에게 서비스를 제공==합니다. 이 회사는 수백만 건의 금융 거래 세부 정보를 ==다른 여러 내부 애플리케이션과 공유==할 수 있는 ==확장 가능한 거의 실시간== 솔루션이 필요합니다. 또한 지연 시간이 짧은 검색을 위해 문서 데이터베이스에 저장하기 전에 ==민감한 데이터를 제거==하기 위해 트랜잭션을 처리해야 합니다. 이러한 요구 사항을 충족하기 위해 솔루션 설계자는 무엇을 권장해야 합니까? 

A. 트랜잭션 데이터를 Amazon DynamoDB 에 저장합니다. 쓰기 시 모든 트랜잭션에서 민감한 데이터를 제거하도록 DynamoDB 에서 규칙을 설정합니다. DynamoDB 스트림을 사용하여 다른 애플리케이션과 트랜잭션 데이터를 공유합니다. 

B. 트랜잭션 데이터를 Amazon Kinesis Data Firehose 로 스트리밍하여 Amazon DynamoDB 및 Amazon S3 에 데이터를 저장합니다. Kinesis Data Firehose 와 AWS Lambda 통합을 사용하여 민감한 데이터를 제거하십시오. 다른 애플리케이션은 Amazon S3 에 저장된 데이터를 사용할 수 있습니다. 

==C.== 트랜잭션 데이터를 ==Amazon Kinesis Data Streams== 로 스트리밍합니다. AWS ==Lambda== 통합을 사용하여 모든 트랜잭션에서 민감한 데이터를 제거한 다음 ==Amazon DynamoDB== 에 트랜잭션 데이터를 저장합니다. 다른 애플리케이션은 Kinesis 데이터 스트림의 트랜잭션 데이터를 사용할 수 있습니다. 

D. 일괄 처리된 트랜잭션 데이터를 Amazon S3 에 파일로 저장합니다. Amazon S3 에서 파일을 업데이트하기 전에 AWS Lambda 를 사용하여 모든 파일을 처리하고 민감한 데이터를 제거하십시오. 그러면 Lambda 함수가 Amazon DynamoDB 에 데이터를 저장합니다. 다른 애플리케이션은 Amazon S3 에 저장된 트랜잭션 파일을 사용할 수 있습니다.

---

실시간 데이터 처리 → Amazon DynamoDB , Amazon Kinesis, Lambda

민감 데이터 처리 → Lambda

다른 어플리케이션과 공유 → Amazon Kinesis Data Streams
##### Amazon Kinesis Data Streams 
streams 강처럼 여러 어플리케이션으로 데이터를 전송하고 공유한다. 데이터를 실시간 처리한다.
여러 Kinesis Data Streams 애플리케이션이 스트림의 데이터를 공유할 수 있다
예를 들어  첫 번째 애플리케이션은 실행 중인 집계를 계산하고 Amazon DynamoDB 테이블을 업데이트하며, 두 번째 애플리케이션은 데이터를 압축하여 Amazon Simple Storage Service(S3)와 같은 데이터 스토어에 보관할 수 있다.
##### Amazon Kinesis Data Firehose 
강한 물줄기처럼 빠르게 목적지로 데이터를 전달한다.
실시간 스트리밍 데이터를 처리하는 데 강력하다

![](https://i.imgur.com/Du30ETS.png)

##### Amazon DynamoDB
dynamic 동적으로 확장 가능하다. 비관계형 즉 nosql DB이다. 대용량 데이터를 빠르게 읽고 쓰기엔 용이하지만, 민감한 데이터를 제거하는 기능은 없다.
##### Amazon S3 
정적 파일을 빠르고 안정적으로 제공
주로 대규모 데이터 스토리지 솔루션으로 사용되며, 일반적으로 정적 데이터 저장이나 백업, 아카이브 등에 적합 실시간 처리 x

---
### 34
회사는 AWS 에서 다중 계층 애플리케이션을 호스팅합니다. 규정 준수, 거버넌스, 감사 및 보안을 위해 회사는 AWS 리소스의 ==구성 변경 사항을 추적==하고 이러한 리소스에 대한 ==API 호출 기록을 기록==해야 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 

A. AWS CloudTrail 을 사용하여 구성 변경을 추적하고 AWS Config 를 사용하여 API 호출을 기록하십시오. 

==B. AWS Config 를 사용하여 구성 변경을 추적하고 AWS CloudTrail 을 사용하여 API 호출을 기록합니다. ==

C. AWS Config 를 사용하여 구성 변경을 추적하고 Amazon CloudWatch 를 사용하여 API 호출을 기록합니다. 

D. AWS CloudTrail 을 사용하여 구성 변경을 추적하고 Amazon CloudWatch 를 사용하여 API 호출을 기록합니다.

---
##### AWS CloudTrail 
trail 모든 발자취( api 호출 )를 추적한다
##### AWS Config
aws 구성을 감시하고 추적한다
##### Amazon CloudWatch
서버, 네트워크, 애플리케이션 등의 성능 모니터링

---
### 35
한 회사가 AWS 클라우드에서 ==공개 웹 애플리케이션 출시==를 준비하고 있습니다. 아키텍처는 ==Elastic Load Balancer(ELB)== 뒤의 VPC 내 Amazon EC2 인스턴스로 구성됩니다. ==DNS 에는 타사 서비스==가 사용됩니다. 회사의 솔루션 설계자는 대규모 ==DDoS 공격을 감지하고 보호==하기 위한 솔루션을 권장해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? 

A. 계정에서 Amazon GuardDuty 를 활성화합니다. 
B. EC2 인스턴스에서 Amazon Inspector 를 활성화합니다. 
C. AWS Shield 를 활성화하고 여기에 Amazon Route 53 을 할당합니다. 
==D. AWS Shield Advanced 를 활성화하고 ELB 를 할당합니다.==

---
##### Elastic Load Balancer(ELB)
트래픽을 여러 ec2 인스턴스에 분산시킴
##### DDoS 공격 (distributed denial of service)
분산을 방해하며 트래픽 처리를 방해
##### Amazon GuardDuty
네트워크 트래픽보다 더 넓은 보안 감시에 중점 , 비정상적인 API 호출, 이상한 로그인 시도등을 감지
##### Amazon Inspector
어플리케이션 보안 취약점을 평가하지만, ddos 방어 x
##### Amazon Route 53 
dns 수준의 보호와 관련되지만 dns엔 타사 서비스를 이용한다고 되어있음
##### AWS Shield , AWS Shield Advanced
ddos 방어에 적합 방패로 한쪽으로 몰리는 트래픽을 막는다

---
### 1
회사는 ==여러 대륙에 걸쳐== 도시의 온도, 습도 및 대기압에 대한 데이터를 수집합니다. 회사가 매일 각 사이트에서 수집하는 데이터의 평균 볼륨은 ==500GB== 입니다. 각 사이트에는 고속 인터넷 연결이 있습니다. 이 회사는 이러한 모든 글로벌 사이트의 데이터를 단일 ==Amazon S3 버킷==에 ==최대한 빨리 집계==하려고 합니다. 솔루션은 운영 복잡성을 최소화해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

==A. 대상 S3 버킷에서 S3 Transfer Acceleration 을 켭니다. 멀티파트 업로드를 사용하여 사이트 데이터를 대상 S3 버킷에 직접 업로드합니다. ==

B. 각 사이트의 데이터를 가장 가까운 리전의 S3 버킷에 업로드합니다. S3 교차 리전 복제를 사용하여 대상 S3 버킷에 객체를 복사합니다. 그런 다음 원본 S3 버킷에서 데이터를 제거합니다. 

C. AWS Snowball Edge Storage Optimized 디바이스 작업을 매일 예약하여 각 사이트에서 가장 가까운 리전으로 데이터를 전송합니다. S3 교차 리전 복제를 사용하여 대상 S3 버킷에 객체를 복사합니다. 

D. 각 사이트의 데이터를 가장 가까운 리전의 Amazon EC2 인스턴스로 업로드합니다. Amazon Elastic Block Store(Amazon EBS) 볼륨에 데이터를 저장합니다. 정기적으로 EBS 스냅샷을 만들어 대상 S3 버킷이 포함된 리전에 복사합니다. 해당 리전에서 EBS 볼륨을 복원합니다.

---
#### S3 Transfer Acceleration 
Amazon S3의 글로벌 엣지 로케이션 네트워크를 전세계에서 이용, 큰 파일을 작게 나눠 동시에 업로드하는 방법인 멀티파트 업로드를 사용
전세계에서 대량의 데이터를 중앙 S3 버킷으로 직접 업로드 가능
#### 리전별 S3 버킷 업로드 후 교차 리전 복제
복제로 인한 시간 비용 
#### AWS Snowball Edge 사용
대규모 데이터 이전(페타바이트 규모)을 위해 설계되었기에 과하다

---
### 2
회사는 독점 애플리케이션의 로그 파일을 분석할 수 있는 능력이 필요합니다. 로그는 ==Amazon S3 버킷==에 JSON 형식으로 저장됩니다. 쿼리는 간단하고 주문형으로 실행됩니다. 솔루션 설계자는 기존 아키텍처에 대한 최소한의 변경으로 분석을 수행해야 합니다. 솔루션 설계자는 ==최소한의 운영 오버헤드==로 이러한 요구 사항을 충족하기 위해 무엇을 해야 합니까? 

A. Amazon Redshift 를 사용하여 모든 콘텐츠를 한 곳에 로드하고 필요에 따라 SQL 쿼리를 실행합니다. 
B. Amazon CloudWatch Logs 를 사용하여 로그를 저장합니다. Amazon CloudWatch 콘솔에서 필요에 따라 SQL 쿼리를 실행합니다. 
==C. Amazon S3 와 함께 Amazon Athena 를 직접 사용하여 필요에 따라 쿼리를 실행합니다. ==
D. AWS Glue 를 사용하여 로그를 분류합니다. Amazon EMR 에서 임시 Apache Spark 클러스터를 사용하여 필요에 따라 SQL 쿼리를 실행합니다.

---
#### Athena
Athena를 사용하면 별도의 서버를 설정할 필요 없이 (S3에 저장된 데이터를 직접 ) SQL 쿼리를 사용하여 데이터를 분석할 수 있다
s3 json 쿼리 가능
#### Amazon Redshift
S3에서 데이터를 Redshift로 로드하는 과정이 필요
#### Amazon CloudWatch Logs
로그 파일이 이미 S3에 저장되어 있기 때문에 CloudWatch로의 이전이 필요
#### AWS Glue ,Amazon EMR
높은 운영 오버헤드와 기존 아키텍처에 대한 상당한 변경이 요구

---
### 3
회사는 AWS Organizations 를 사용하여 여러 부서의 여러 AWS 계정을 관리합니다. 관리 계정에는 프로젝트 보고서가 포함된 Amazon S3 버킷이 있습니다. 회사는 이 S3 버킷에 대한 ==액세스를 AWS Organizations 의 조직 내 계정 사용자로만 제한==하려고 합니다. ==최소한의 운영 오버헤드==로 이러한 요구 사항을 충족하는 솔루션은 무엇입니까? 

==A. 조직 ID 에 대한 참조와 함께 aws PrincipalOrgID 전역 조건 키를 S3 버킷 정책에 추가합니다.== 

B. 각 부서에 대한 조직 단위(OU)를 만듭니다. aws:PrincipalOrgPaths 전역 조건 키를 S3 버킷 정책에 추가합니다. 

C. AWS CloudTrail 을 사용하여 CreateAccount, InviteAccountToOrganization, LeaveOrganization 및 RemoveAccountFromOrganization 이벤트를 모니터링합니다. 그에 따라 S3 버킷 정책을 업데이트합니다. 

D. S3 버킷에 액세스해야 하는 각 사용자에 태그를 지정합니다. aws:PrincipalTag 전역 조건 키를 S3 버킷 정책에 추가합니다.

---

A) 조직 ID를 사용 => 조직에 속한 계정만이 접근 가능하다. 
B) 조직 단위(OU)를 사용하는 방법 => 부서 별로 다르게 정책을 설정할 수 있다.
C) AWS CloudTrail => 상세한 aws 활동을 기록 가능하게 한다
D) 태그 => 각 사용자에 특정 태그를 지정하고, 이 태그를 기반으로 버킷에 접근 가능하게 하지만 태그 관리 해줘야한다.

---
### 4
애플리케이션은 ==VPC 의 Amazon EC2 인스턴스==에서 실행됩니다. 애플리케이션은 Amazon S3 버킷에 저장된 로그를 처리합니다. EC2 인스턴스는 ==인터넷 연결 없이 S3 버킷에 액세스==해야 합니다. Amazon S3 에 대한 프라이빗 네트워크 연결을 제공하는 솔루션은 무엇입니까? 

==A. S3 버킷에 대한 게이트웨이 VPC 엔드포인트를 생성합니다. ==
B. Amazon CloudWatch Logs 로 로그를 스트리밍합니다. 로그를 S3 버킷으로 내보냅니다. 
C. Amazon EC2 에 인스턴스 프로파일을 생성하여 S3 액세스를 허용합니다. 
D. S3 엔드포인트에 액세스하기 위한 프라이빗 링크가 있는 Amazon API Gateway API 를 생성합니다.

---

A) S3에 대한  VPC 엔드포인트를 설정하면, EC2 인스턴스가 인터넷을 거치지 않고 직접 S3 버킷에 접근할 수 있음
- vpc(virtual private cloud) 내에서 EC2 인스턴스를 배치하면, 가상 네트워킹 환경에서 실행되는 가상 서버를 설치하는거랑 동일하고, 사설 네트워크에 배치한다면 외부 인터넷이랑 분리된 환경을 제공한다.

B) 로그를 수집하고 보관하는 데 유용하지만, EC2 인스턴스가 S3 버킷에 직접 접근하는 것은 아님
C) Amazon EC2 에 인스턴스 프로파일을 생성하면 S3버킷에 접근 가능하나, 인터넷 없이는 x
D) VPC 엔드포인트를 직접 사용하는 것보다 덜 직관적이다

---
### 5
회사는 사용자 업로드 문서를 ==Amazon EBS 볼륨에 저장하는 단일 Amazon EC2 인스턴스==를 사용하여 AWS 에서 웹 애플리케이션을 호스팅하고 있습니다. 더 나은 확장성과 가용성을 위해 이 회사는 아키텍처를 복제하고 다른 가용 영역에 두 번째 EC2 인스턴스와 EBS 볼륨을 생성하여 Application Load Balancer 뒤에 배치했습니다. 이 변경을 완료한 후 사용자는 웹 사이트를 새로 고칠 때마다 문서의 일부 또는 다른 하위 집합을 볼 수 있지만 모든 문서를 동시에 볼 수는 없다고 보고했습니다. 솔루션 설계자는 사용자가 ==모든 문서를 한 번에 볼 수 있도록== 무엇을 제안해야 합니까? 

A. 두 EBS 볼륨에 모든 문서가 포함되도록 데이터를 복사합니다. 
B. 문서가 있는 서버로 사용자를 안내하도록 Application Load Balancer 를 구성합니다. C. 두 EBS 볼륨의 데이터를 Amazon EFS 로 복사합니다. 새 문서를 Amazon EFS 에 저장하도록 애플리케이션을 수정합니다. 
D. 두 서버 모두에 요청을 보내도록 Application Load Balancer 를 구성합니다. 올바른 서버에서 각 문서를 반환합니다.

---
문제 상황
Application Load Balancer 뒤에 EC2 인스턴스가 각각 Amazon EBS 볼륨에 데이터를 저장하고 있다. 

-  Amazon EBS(elastic block store) : 블록 레벨 스토리지 볼륨으로, 네트워크 연결을 통해 EC2 인스턴스와 연결된다. 

A) 데이터를 복사하여 서버마다 같은 데이터를 갖게 하는 것은 비효율적이다.
B) 로드벨린서가 sticky session으로 구성되면 서버 다운시 문제 생길 수 있다. 
C) Amazon EFS (elastic file system) 파일 스토리지를 두어 데이터를 중앙에서 관리 가능하게 한다.
D) 모든 서버에게 요청 보내는 것은 비효율적이다.

---
### 6
회사는 ==NFS 를 사용하여 온프레미스 네트워크 연결 스토리지==에 ==대용량 ==비디오 파일을 저장합니다. 각 비디오 파일의 크기 범위는 1MB 에서 500GB 입니다. 총 스토리지는 70TB 이며 더 이상 증가하지 않습니다. 회사는 비디오 파일을 Amazon S3 로 마이그레이션하기로 결정합니다. 회사는 가능한 ==한 최소한의 네트워크 대역폭==을 사용하면서 가능한 한 빨리 비디오 파일을 마이그레이션해야 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까? 

A. S3 버킷을 생성합니다. S3 버킷에 대한 쓰기 권한이 있는 IAM 역할을 생성합니다. AWS CLI 를 사용하여 모든 파일을 S3 버킷에 로컬로 복사합니다. 

B. ==AWS Snowball Edge 작업을 생성합니다. 온프레미스에서 Snowball Edge 장치를 받습니다. Snowball Edge 클라이언트를 사용하여 장치로 데이터를 전송합니다. AWS 가 데이터를 Amazon S3 로 가져올 수 있도록 디바이스를 반환합니다. ==

C. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 퍼블릭 서비스 엔드포인트를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에서 새 NFS 파일 공유를 생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다. 

D. 온프레미스 네트워크와 AWS 간에 AWS Direct Connect 연결을 설정합니다. 온프레미스에 S3 파일 게이트웨이를 배포합니다. S3 파일 게이트웨이에 연결할 공용 VIF(가상 인터페이스)를 생성합니다. S3 버킷을 생성합니다. S3 파일 게이트웨이에서 새 NFS 파일 공유를 생성합니다. 새 파일 공유가 S3 버킷을 가리키도록 합니다. 기존 NFS 파일 공유에서 S3 파일 게이트웨이로 데이터를 전송합니다.

---

- NFS (Network File System) 를 사용하여 온프레미스 : 파일 공유 프로토콜을 이용하여, 조직이 자체 서버에서 파일 저장 시스템을 구축한 환경을 말한다. 

A) AWS CLI를 사용하여 직접 S3 버킷으로 파일을 전송하기에 대량 데이터는 적합하지 않다.
B) Snowball Edge는 대용량 데이터를 빠르게 AWS로 전송 가능하게 한다. 네트워크 대역폭을 거의 사용하지 않는다. 
C) S3 파일 게이트웨이는 온프리메스 환경에서 NFS 프로토콜을 이용하지만 네트워크 사용 대역폭이 넓다.
D) AWS Direct Connect 설치와 네트워크 대역폭을 많이 차지한다. 

---
### 7
회사에 들어오는 ==메시지를 수집==하는 응용 프로그램이 있습니다. 그러면 ==수십 개의 다른 애플리케이션과 마이크로서비스가 이러한 메시지를 빠르게 소비==합니다. ==메시지 수==는 급격하게 변하며 때로는 ==초당 100,000 개로== ==갑자기 증가==하기도 합니다. 이 회사는 ==솔루션을 분리==하고 확장성을 높이고자 합니다. 어떤 솔루션이 이러한 요구 사항을 충족합니까?

A. Amazon Kinesis Data Analytics 에 대한 메시지를 유지합니다. 메시지를 읽고 처리하도록 소비자 애플리케이션을 구성합니다. 

B. Auto Scaling 그룹의 Amazon EC2 인스턴스에 수집 애플리케이션을 배포하여 CPU 지표를 기반으로 EC2 인스턴스 수를 확장합니다. 

C. 단일 샤드를 사용하여 Amazon Kinesis Data Streams 에 메시지를 씁니다. AWS Lambda 함수를 사용하여 메시지를 사전 처리하고 Amazon DynamoDB 에 저장합니다. 메시지를 처리하기 위해 DynamoDB 에서 읽도록 소비자 애플리케이션을 구성합니다. 

==D. 여러 Amazon Simple Queue Service(Amazon SQS) 구독이 있는 Amazon Simple Notification Service(Amazon SNS) 주제에 메시지를 게시합니다. 대기열의 메시지를 처리하도록 소비자 애플리케이션을 구성합니다.==

---

A) 실시간 데이터 스트림 분석에 유리하지만, 확장성에 취약하다
B) 각 인스턴스가 메시지를 독립적으로 처리하므로 메시지 관리와 분배에 오류가 생길 수 있다.
C)  단일 샤드는 데이터 베이스를 다중화 시킨게 아니기에 초당 100000개 처리하기 적합하지 않다.
D) 요청을 ==Amazon SQS== 로 라우팅하여 요청응 분리하여, 모든 구독 대기열에 메시지들 전부 복제한다.

---
### 8
회사에서 ==분산 애플리케이션을 AWS 로 마이그레이션==하고 있습니다. 애플리케이션은 다양한 워크로드를 처리합니다. 레거시 플랫폼은 여러 컴퓨팅 노드에서 작업을 조정하는 기본 서버로 구성됩니다. 이 회사는 탄력성과 확장성을 극대화하는 솔루션으로 애플리케이션을 현대화하려고 합니다. 솔루션 설계자는 이러한 요구 사항을 충족하기 위해 아키텍처를 어떻게 설계해야 합니까? 

A. 작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 예약된 조정을 사용하도록 EC2 Auto Scaling 을 구성합니다. 

B. 작업의 대상으로 Amazon Simple Queue Service(Amazon SQS) 대기열을 구성합니다. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 컴퓨팅 노드를 구현합니다. 대기열 크기에 따라 EC2 Auto Scaling 을 구성합니다. 

C. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 AWS CloudTrail 을 구성합니다. 기본 서버의 부하를 기반으로 EC2 Auto Scaling 을 구성합니다. 

D. Auto Scaling 그룹에서 관리되는 Amazon EC2 인스턴스로 기본 서버와 컴퓨팅 노드를 구현합니다. 작업의 대상으로 Amazon EventBridge(Amazon CloudWatch Events)를 구성합니다. 컴퓨팅 노드의 부하를 기반으로 EC2 Auto Scaling 을 구성합니다.

---
- Amazon Simple Queue Service(Amazon SQS) 대기열 : 
- AWS CloudTrail
- Amazon EventBridge(Amazon CloudWatch Events)